### 什么是内存管理
1. 内存是计算机最重要的资源之一，内存管理也是操作系统最重要的任务之一。如何表示、组织、分配和回收内存资源是内存管理的重要内容。
2. 操作系统内存管理的基本模式也经历了好几代的发展。
   - 原始内存管理。最初，内存管理十分的简陋，大家都运行在物理内存空间上，内核和进程运行在一个空间中，内存分配算法有首次适应算法、最佳适应算法和最差适应算法等。这样的内存管理方式问题是很明显的，内核与进程之间没有做隔离，进程可以随意访问(干扰、窃取)内核的数据。并且进程与内核没有权限的区分，进程可以随意做一些敏感的操作。还有一个问题就是当时的物理内存非常少，能同时运行的进程非常少，运行进程吞吐量比较少。
   - 分段内存管理。分段内存管理需要硬件的支持和软件的配合。在分段内存中，软件可以把物理内存分成一个一个的段，每个段都有段基址和长度，还有段类型和段权限。段基址与段长度限定了访问内存的一个段的范围，可以防止内存访问越界。段与段之间也可以互相访问，但不能随意访问，必须符合相应的权限要求。段类型也正好对应了程序中的代码段和数据段，代码段不可写，数据段有的可读，这样又增加了一层安全性。其中，内核的代码段和数据段都设置为特权段，进程的代码段和数据段设为用户段，就实现了进程与内核的隔离。并且CPU指令也会分为特权级指令和用户级指令，限制了进程的操作范围。段式内存管理很好地解决了安全上的问题，但是存在效率问题。首先，段的大小长度不一，当物理内存紧张时，需要把进程一部分内存上的数据换出到外村中，这时就会导致系统性能抖动。其次，频繁地申请释放段会产生大量的外部碎片，使得明明系统还有很多空闲物理内存，但无法满足进程的内存请求。
   - 分页内存管理。分页内存管理引入了虚拟内存空间的概念，又称为虚拟内存管理。同样需要硬件的支持和配合。在分页模式中，CPU发出的寻址指令的地址都是虚拟地址，经过CPU中的MMU，把虚拟地址转化为物理地址，最后才将这个物理地址送到总线上寻址。MMU把虚拟地址转化为物理地址的过程需要页表的支持，页表则是由内核负责创建和维护的。一套页表可以表达一个虚拟内存空间，不同的进程拥有不用的页表，哪个进程运行就切换到那个进程的页表。于是一个进程就只能访问自己的虚拟内存空间，实现了进程与进程件的相互隔离。虚拟内存空间又分为两部分，内核空间和用户空间。内核空间只有一个，所有进程共享，用户空间每个进程一个。内核运行在内核空间，进程运行在用户空间，内核空间有特权级，用户空间无特权，又实现了内核与进程的隔离。并且每个页大小相等，32位系统下为4KB大小，通过MMU映射，将连续的虚拟页分散到不连续的物理页框中，解决了外碎片的问题。与外存交换也以页为单位，消除了交换时的抖动。
这样看来，分页内存管理不仅实现了分段内存管理的功能，还有额外的优点。于是分段内存管理就没有存在的意义了。但是这里有一个历史包袱问题，x86硬件为了兼容之前的平台，在x86 32位机器上，分段机制和分页机制时并存的。所以，大多数操作系统都在逻辑上屏蔽掉分段机制，但是无法禁用。主要方法就是所有段的基址都是0，长度都是最大值，就相当于不分段了。段机制无法禁用的原因是因为CPU特权级是在段中实现的(全局描述符中的权限位),分页机制没有单独的CPU特权级。

### 内存管理的目标是什么？
1. 安全性。进程之间的隔离，进程与内核的隔离。
2. 减少内存碎片，包括外部碎片和内部碎片。
3. 内存分配接口灵活多样，同时满足多种不同的内存分配需求。既要满足大块连续内存分配需求，又能满足小块零碎内存需求。
4. 内存分配效率要高。
5. 提高物理内存的利用率，比如及时回收物理内存。

### 具体说说是怎么建立内存管理的。
1. 要想建立分页内存管理，先要建立分段内存管理。之前bootblock将内核文件加载到1M内存处，但是实际上经过链接后的内核可执行文件的地址是虚拟地址，通过链接脚本指定为0xC0100000处，也就是位于虚拟内存空间的内核空间中。这时就产生了链接地址与执行地址不一致的情况。此时分页机制还没有开始，所以必须建立正确的分段机制。方法就是将所有段的基址设为-0xC0000000，这样就将高地址的内核空间映射到了地地址的物理空间中，分段模式也就建立起来了。
2. 建立结构体page描述物理页框的信息，包括是否分配、引用计数、挂载的链表等等。使用bootblock探测到的物理内存信息初始化空闲物理页框数组，并保存在内存的某处地方。
3. 用page数组初始化物理内存分配器。分配器的工作就是以某种结构组织和记录空闲页框，以某种算法分配和回收物理页框。项目中使用的是首次适配算法分配物理页框。
4. 向物理内存分配器请求一个物理页框作为顶级页目录，修改其中的页表项。页表项中记录的就是实际的物理起始地址和访问权限。修改之后，使得0xC0000000的高线性地址映射到从0开始的物理地址中。此时，分段机制将高虚拟地址映射到了低线性地址中，所以此时要重新加载新的段描述符，在逻辑上屏蔽段机制，使得虚拟地址与线性地址对等映射。
5. 设置CR3寄存器的值为顶级页目录所在页框的起始地址，设置CR0中的标志位，开启分页模式。至此分页模式就建立起来了。

### 怎么实现虚拟地址到物理地址的映射的？
1. 32位的虚拟地址被分为10 10 12三个部分。分别是一级页表索引、二级页表索引和页内偏移。CPU发出某个访存指令时，此时顶级页目录一定是存在的，也就是CR3寄存器的值一定是有效的。
2. MMU根据CR3寄存器的值访问相应的物理内存，得到页目录。用一级页表索引访问到相应的页目录项。如果页目录项有效(不为0并且存在位为1)，就得到了一级页表的物理地址。如果页目录项无效，内核会向物理内存分配器申请一个页框，并且设置好相应的权限后，将这个物理页框的物理地址填入到页目录项中。
3. 到了第三步，用二级页表索引访问一级页表的页表项。如果页表项有效，就得到了二级页表的起始物理地址，加上页内偏移就是此虚拟地址映射到的物理地址。如果页表项无效，内核会向物理内存分配器申请一个页框，并且设置好相应的权限后，将此物理页框的物理地址填入到页目表项中。

### CPU怎样访问页目录项或者页表项？
1. 如果MMU指令访问的页目录项或者页表项无效的化，会触发一次缺页异常，执行流会转到缺页中断服务程序，并且CR2中记录引发缺页的线性地址。
2. 在缺页中断服务程序中，要修改对应的页目录项或者页表项。由于开启了分页模式，任何CPU的访存都要经过MMU映射，所以不能直接用CR3寄存器中的值去访问顶级页目录。进程中保存了顶级页目录的虚拟地址，用此虚拟地址就可以访问并修改相应的页目录项或页表项，完成缺页异常处理。
3. 简单来说，页表项或页目录项中记录的值是物理地址，而在CPU中访问这些页表本身则需要转换程虚拟地址。

### 内存分配算法有哪些？
1. 首次适配算法: 每次从头开始找，找到第一个能满足大小的空闲分区。实现：以链表的形式组织空闲分区，空闲分区的第一个页框记录当前分区的空闲页框数量，如果满足请求，就分配出去，并修改相应分区。优点：实现简单。缺点是：使得内存地地址处出现很多小的空闲分区，而每次查找都要经过这些分区，增加了查找的开销。
2. 最佳适配算法：为了保证当大进程到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区。空闲区按容量递增次序链接，每次分配内存时顺序查找空闲分区链表，找到大小能满足的第一个空闲分区。缺点就是：每次都使用最小分区进行分配，越来越多的难以利用的小内存块会被留下来，产生很多外部碎片。
3. 最坏适配算法。解决最佳适配算法留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后的空闲区就不会太小，更方便使用。实现方法时按分区容量递减次序链接，每次分配内存时顺序查找空闲分区链，找到满足请求的第一个空闲分区。缺点是导致较大的连续空闲分区迅速被用完，如果之后有大进程到达，就没有内存可以使用了。
4. 临近适配算法。首次适配算法每次都从链表头开始查找，并且分配多次后，低地址部分会出现很多小的空闲分区，而每次查找都要经过这些分区，增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能跳过低地址部分分区。实现方法:循环链表。缺点是导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，导致了高地址空间被划分程小分区，最后无大分区可用。

### 什么是伙伴系统?
1. 伙伴系统是一个物理页框分配器，分配的最小单位是页。相邻的1页 2页 4页 即2的阶次个页成为伙伴。伙伴系统对外提供的接口只能分配某一阶的页块，并不能随意分配若干个页。
2. 当分配n阶页块时，伙伴系统会优先查找n阶页块的链表，如果不为空的化就拿出来一个进行分配。如果为空，就去找n+1阶页块的链表，如果不为空，就拿出来一个，并分为两个n阶页块，一个分配，一个插入到n阶页块的链表中。用户归还内存块时，并不是直接还给对应的链表就行了。而是会先进行合并。假设归还0阶页块，页框号为5。如果此时发现4号页框也是空闲的，就会合并4 5号页框成为一个1阶页块。判断伙伴的要求是：相邻，首页页框号能被2^(n)整除。然后把这个页块插入到1阶链表中。此时，如果发现6 7页块也是空闲的，就继续合并。


### 什么是slab分配器
1. 无论是哪种算法的物理页框分配器，其分配的最小单位都是页框。但内核中有大量的同一类型结构体的分配请求，比如说进程控制块task_struct。如果用页框分配器分配明显不合适，产生很多内碎片，而如果自己分配一个页框再进行分割，管理又很麻烦。所以就提供了小块内存的分配器，slab。
2. Slab的基本思想就是先从伙伴系统中分配一些页面，然后把这些页面切割程一个个同样大小的基本块，用户就可以从slab中申请分配一个同样大小的内存块了。如果slab中的内存不够用了，它会再向伙伴系统中进行申请。

### 什么是Kmalloc
1. 内存中还有一些偶发的零碎内存分配需求，一个模块如果仅仅为了分配一次5字节的内存，就去创建一个slab。明显不划算。为此，内核创建了一个零碎内存分配器kmalloc，用户可以直接请求kmalloc分配若干个字节的内存，其底层还是用的slab机制。
2. kmalloc启动时会预先创建一些不同大小的slab，用户请求分配任意大小的内存，kmalloc都会找到大小刚刚满足的slab中去分配内存。